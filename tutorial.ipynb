{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "389c0f22",
   "metadata": {},
   "source": [
    "# HPC-Opsによる実験管理チュートリアル\n",
    "\n",
    "チュートリアルでは，optunaを用いたハイパーパラメータ探索の例を使って基本的なHPC-Opsの利用方法を説明します．\n",
    "扱う実験内容については以下の書籍を参考にしてください．\n",
    "\n",
    "[Optunaによるブラックボックス最適化 Chaper2 Section 3.4](https://books.google.co.jp/books/about/Optuna%E3%81%AB%E3%82%88%E3%82%8B%E3%83%96%E3%83%A9%E3%83%83%E3%82%AF%E3%83%9C%E3%83%83%E3%82%AF%E3%82%B9.html?id=geatEAAAQBAJ&source=kp_book_description&redir_esc=y)\n",
    "- code: https://github.com/pfnet-research/optuna-book/blob/master/chapter2/list_2_16_optimize_rf_gb_with_conditional_search_space.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b7798fb",
   "metadata": {},
   "source": [
    "## 必要なモジュールのインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2ce33741",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import os\n",
    "import pickle\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"app/\")\n",
    "\n",
    "import wandb\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from app.schema.create_job_schema import InputModel\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b59dc6",
   "metadata": {},
   "source": [
    "## 実験の流れ\n",
    "\n",
    "### 1. Flow Logicの作成\n",
    "### 2. logicファイルをwandbにアップロード\n",
    "### 3. 利用する生データ等があればwandbにアップロード\n",
    "### 4. ローカルからHPCに実験の実行をリクエストする．\n",
    "\n",
    "上記を順に行うことで1つの実験が完了します．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfbc0518",
   "metadata": {},
   "source": [
    "## 1. Flow Logicの作成\n",
    "- HPC-Opsでは，実験ロジックをBaseFlowLogicクラスを継承したMyFlowLogicクラスに記述し，これをHPC側から読み込むことで実験を行います．\n",
    "- HPC-Opsでは，実験をその中で並列実行可能なタスクに分解して実行することで高速に実験を行います．\n",
    "- MyFlowLogicでは実験の準備(task_scheduler)，実験の実行(run_task)，実験結果の集約(create_result)の3つのメソッドを実装する必要があります．\n",
    "    - task_scheduler(self) -> List[Dict[str, Any]]:\n",
    "        - ここでは，実験に使うデータやパラメータ等のオブジェクトを並列可能なタスクへの入力として前処理します．\n",
    "        - 出力の各要素はrun_taskメソッドに入力されます．\n",
    "    - run_task(self, **kwargs) -> Any:\n",
    "        - ここでは，実験の実行ロジックを記述します．task_schedulerの要素である辞書を受け取り，実行結果を出力します．\n",
    "        - 入力は並列実行するタスクごとに異なる値(task_scheduler出力の各要素)が与えられ，共通化されたrun_taskメソッドにより各タスクを実行します．\n",
    "    - create_result(self, result_set: List[Any]) -> None:\n",
    "        - ここでは，各タスクの実行結果を受け取り，実行結果から最終的な実験結果を集約します．\n",
    "        - 集約結果はwandbによって管理します．"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0e621b",
   "metadata": {},
   "source": [
    "- 本チュートリアルでは，scikit-learnを使った機械学習によるタスクのハイパーパラメータ探索を扱います．\n",
    "- 手順1のFlow Logicとして`flow_logics/optuna_example.py`を利用します."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9537d2",
   "metadata": {},
   "source": [
    "## 2. logicファイルをwandbにアップロード\n",
    "- `flow_logics/optuna_example.py`をwandbのArtifactsにアップロードします．\n",
    "- HPC-Ops利用時の注意点として，アップロードするファイル名とArtifact名を統一する必要があります．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b47221d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 実験のproject, group, jobtypeを定義する.\n",
    "project = \"hpc-ops-tutorial\"\n",
    "group = \"optuna-example\"\n",
    "jobtype = \"my-first-tutorial\"\n",
    "\n",
    "wandb_apikey = os.environ.get(\"WANDB_APIKEY\")\n",
    "# wandbにログイン\n",
    "wandb.login(key=wandb_apikey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ce92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## wandbにoptuna_example.pyをアップロード\n",
    "run = wandb.init(\n",
    "    project=project, group=group, job_type=jobtype, name=\"upload-flow-logic\"\n",
    ")\n",
    "logic_artifact = wandb.Artifact(name=\"optuna_example\", type=\"flow logic\")\n",
    "logic_artifact.add_file(local_path=\"flow_logics/optuna_example.py\")\n",
    "run.log_artifact(logic_artifact)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6efd483d",
   "metadata": {},
   "source": [
    "## 3. 利用する生データ等があればwandbにアップロード\n",
    "- scikit-learnのデータセットを利用するため，データを作成し，wandbにアップロードします．\n",
    "- 手順4においてデータセット名をパラメータとして指定することでFlow Logic内で読み込みます．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26fb3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 利用データを作成し，wandbにアップロード\n",
    "\n",
    "# データ作成\n",
    "data = fetch_openml(name=\"adult\")\n",
    "os.makedirs(\"data/\", exist_ok=True)\n",
    "with open(\"data/optuna-example.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)\n",
    "\n",
    "# wandbにアップロード\n",
    "run = wandb.init(project=project, group=group, job_type=jobtype, name=\"upload-dataset\")\n",
    "dataset_artifact = wandb.Artifact(name=\"optuna-example\", type=\"dataset\")\n",
    "dataset_artifact.add_file(local_path=\"data/optuna-example.pkl\")\n",
    "run.log_artifact(dataset_artifact)\n",
    "run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6844891d",
   "metadata": {},
   "source": [
    "## 4. ローカルからHPCに実験の実行をリクエストする．\n",
    "\n",
    "- HPCのFastAPIサーバーに対して実験ジョブの投入リクエストを行います．\n",
    "- リクエストボディとして以下のようなInputModelをjsonに変換してリクエストします．\n",
    "    - InputModel(BaseModel):\n",
    "        - node: Optional[int]\n",
    "            - ノード数の指定（１ノード以上の資源を使用する場合に必須）．デフォルトは`None`．\n",
    "        - vnode_core: Optional[int]\n",
    "            - コア数の指定（ノードグループAで１ノード未満の資源を利用する場合に必須）．デフォルトは`None`．\n",
    "        - gpu: Optional[int]\n",
    "            - GPU数の指定（ノードグループB，Cで１ノード未満の資源を利用する場合に必須）．デフォルトは`None`．\n",
    "        - elapse: Optional[str]\n",
    "            - ジョブの実行時間の上限を指定．デフォルトは`01:00:00`．\n",
    "        - params: Optional[dict]\n",
    "            - 実験に関するパラメータ設定．\n",
    "        - project: str\n",
    "            - wandbのプロジェクト名．必須．\n",
    "        - group: Optional[str]\n",
    "            - wandbのプロジェクトグループ名．\n",
    "        - jobtype: Optional[str]\n",
    "            - wandbのプロジェクトジョブタイプ名．\n",
    "        - run: Optional[str]\n",
    "            - wandbのプロジェクトラン名．\n",
    "        - flow_logic: str\n",
    "            - wandbに保存したflow logicファイルの名前と使用バージョン．デフォルトは`sample_flow_logic:latest`．"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec63f5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"http://127.0.0.1:8000\"\n",
    "endpoint = \"/create-job\"  # \"/create-local-job\"\n",
    "\n",
    "# リクエストボディ作成\n",
    "data = InputModel(\n",
    "    node=None,\n",
    "    vnode_core=1,\n",
    "    gpu=None,\n",
    "    elapse=\"02:00:00\",\n",
    "    params={\n",
    "        \"dataset\": \"optuna-example:v0\",\n",
    "        \"clf\": (\"clf\", (\"RF\", \"GB\")),\n",
    "        \"rf_max_depth\": (\"rf_max_depth\", 2, 32),\n",
    "        \"rf_min_samples_split\": (\"rf_min_samples_split\", 0, 1),\n",
    "        \"gb_max_depth\": (\"gb_max_depth\", 2, 32),\n",
    "        \"gb_min_samples_split\": (\"gb_min_samples_split\", 0, 1),\n",
    "    },\n",
    "    project=project,\n",
    "    group=group,\n",
    "    jobtype=jobtype,\n",
    "    flow_logic=\"optuna_example:v0\",\n",
    ").model_dump()\n",
    "# HPCにリクエスト\n",
    "timeout = aiohttp.ClientTimeout(total=3600 * 2)  # タイムアウトを2時間に設定\n",
    "async with aiohttp.ClientSession(timeout=timeout) as session:\n",
    "    async with session.post(base_url + endpoint, json=data) as r:\n",
    "        res = await r.json()\n",
    "res"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
